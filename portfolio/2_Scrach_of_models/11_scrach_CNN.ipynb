{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "taLCvB8StWf-"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UT92i_3sBhh_"
   },
   "source": [
    "### Forword　手計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueZTF3okp-YT"
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])#入力情報\n",
    "w = np.array([3, 5, 7])#フィルター\n",
    "b = np.array([1])#バイアス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PT-ZkRe0vJaL",
    "outputId": "be3ba097-738f-4ea7-9478-95328aba22ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1スライド目\n",
    "alpha1 = np.dot(x[0:3], w.T) + b\n",
    "alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JE8A6mWQvJVW",
    "outputId": "536b8d85-8fea-4638-855b-1a2948e7ef43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2スライド目\n",
    "alpha2 = np.dot(x[1:4], w.T) + b\n",
    "alpha2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 畳み込んだ結果\n",
    "np.array([alpha1[0], alpha2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY5iYpALGNhV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#わかりにくいけどこれでもできる\n",
    "\n",
    "a_re =  np.convolve(x[::-1],w, mode='valid') +b\n",
    "\n",
    "x[::-1]#反対にするcode\n",
    "\n",
    "a = a_re[::-1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4MaXuA8tjzm"
   },
   "outputs": [],
   "source": [
    "#Answer of Forword\n",
    "a = np.array([35, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6--gufFvJSJ"
   },
   "source": [
    "### Backward 手計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師データとの誤差が以下のdelta_aだった時のバックワードの計算\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "b3HosNhHCrIr",
    "outputId": "72e5d0b6-be26-419e-987b-82380ca52b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バイアス\n",
      "[30]\n",
      "\n",
      "フィルター\n",
      "[ 50  80 110]\n",
      "\n",
      "入力\n",
      "[ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "# バイアス項\n",
    "delta_B = delta_a[0] + delta_a[1]\n",
    "\n",
    "# フィルター\n",
    "delta_W0 = delta_a[0]*x[0] + delta_a[1]*x[1]\n",
    "delta_W1 = delta_a[0]*x[1] + delta_a[1]*x[2]\n",
    "delta_W2 = delta_a[0]*x[2] + delta_a[1]*x[3]\n",
    "\n",
    "# 入力\n",
    "delta_x0 = delta_a[0]*w[0]\n",
    "delta_x1 = delta_a[0]*w[1] + delta_a[1]*w[0]\n",
    "delta_x2 = delta_a[0]*w[2] + delta_a[1]*w[1]\n",
    "delta_x3 = delta_a[1]*w[2]\n",
    "\n",
    "print('バイアス')\n",
    "print(np.array([delta_B]))\n",
    "print()\n",
    "\n",
    "print('フィルター')\n",
    "delta_W = np.array([delta_W0, delta_W1, delta_W2])\n",
    "print(delta_W)\n",
    "print()\n",
    "\n",
    "print('入力')\n",
    "delta_x = np.array([delta_x0, delta_x1, delta_x2, delta_x3])\n",
    "print(delta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Backward\n",
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# これでもできる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = w*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = w*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_x_hand = np.zeros([4])\n",
    "delta_x_hand[0:3] += right\n",
    "delta_x_hand[1:4] += left\n",
    "delta_x_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_left = x[0:3]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY5iYpALGNhV"
   },
   "outputs": [],
   "source": [
    "w_right = x[1:4]*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50,  80, 110])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w_hand = w_left + w_right\n",
    "delta_w_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aexdaFoDNu0c"
   },
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFG9gWmAOzVt"
   },
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <msub>\n",
    "    <mi>N</mi>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>o</mi>\n",
    "      <mi>u</mi>\n",
    "      <mi>t</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <mfrac>\n",
    "    <mrow>\n",
    "      <msub>\n",
    "        <mi>N</mi>\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mi>i</mi>\n",
    "          <mi>n</mi>\n",
    "        </mrow>\n",
    "      </msub>\n",
    "      <mo>+</mo>\n",
    "      <mn>2</mn>\n",
    "      <mi>P</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mi>F</mi>\n",
    "    </mrow>\n",
    "    <mi>S</mi>\n",
    "  </mfrac>\n",
    "  <mo>+</mo>\n",
    "  <mn>1</mn>\n",
    "  <mspace linebreak=\"newline\" />\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EXE2FVvOAtZ"
   },
   "source": [
    "N\n",
    "o\n",
    "u\n",
    "t\n",
    " : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "N\n",
    "i\n",
    "n\n",
    " : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "P\n",
    " : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "F\n",
    " : フィルタのサイズ\n",
    "\n",
    "\n",
    "S\n",
    " : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mhujROoXNuP7",
    "outputId": "a40adf1b-0e36-438a-886c-3bf409143106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = len(x)\n",
    "P_size = 0\n",
    "F_size = len(w)\n",
    "S_size = 1\n",
    "n_out = ((n_in + 2*P_size -F_size)/S_size)+1\n",
    "n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EuAAk09kvkUb"
   },
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "gFhC-snKZcKr",
    "outputId": "55abbc94-88ad-4b29-fe26-914ea4cc6a5d"
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhZDgFPtegr0"
   },
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "frwYsAAIsph4",
    "outputId": "b4867c38-6aee-49d9-b69f-654b69de51d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.zeros([3, 2])\n",
    "for i in range(3):\n",
    "    for k in range(2):\n",
    "        a = (x[:, k:k+3]*w[i]).sum() + b[i]\n",
    "        result[i,k] = a\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DI0EnBWDwEWP"
   },
   "outputs": [],
   "source": [
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "\n",
    "b_ = np.array([1,2,3])\n",
    "\n",
    "# フォワードの出力\n",
    "out_ = np.array([[21,29],\n",
    "                [18,25],\n",
    "                [18,24]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward関数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YSAfNTn19HW"
   },
   "outputs": [],
   "source": [
    "def forword(x, w, b):\n",
    "    result = np.zeros([3, 2])\n",
    "    for i in range(3):\n",
    "        for k in range(2):\n",
    "            a = (x[:, k:k+3]*w[i]).sum() + b[i]\n",
    "            result[i,k] = a\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "XZbmah_e2WUY",
    "outputId": "de49e591-8b18-4f19-f563-3cd6329f4f04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 29.],\n",
       "       [18., 25.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forword(x_, w_, b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backword計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_PxsdbQ2dwT"
   },
   "outputs": [],
   "source": [
    "loss_ = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])\n",
    "\n",
    "\n",
    "# バックワードの勾配\n",
    "x_delta = np.array([[125,230,204,113],\n",
    "                    [102,206,195,102]])\n",
    "\n",
    "\n",
    "w_delta = np.array([[[31,51,71],[51,71,91]],\n",
    "                    [[102,169,236],[169,236,303]],\n",
    "                    [[164,272,380],[272,380,488]]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delta_W手計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Vsvn18bKOus"
   },
   "outputs": [],
   "source": [
    "left_x = x_[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAgwbBT1KOo_"
   },
   "outputs": [],
   "source": [
    "right_x = x_[:, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "1_cRFnqwKN85",
    "outputId": "018f255e-0f92-47cc-cbcd-d90578c2f823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 51, 71],\n",
       "       [51, 71, 91]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w1 = left_x*loss_[0, 0] + right_x*loss_[0, 1]\n",
    "delta_w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 169, 236],\n",
       "       [169, 236, 303]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w2 = left_x*loss_[1, 0] + right_x*loss_[1, 1]\n",
    "delta_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164, 272, 380],\n",
       "       [272, 380, 488]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w3 = left_x*loss_[2, 0] + right_x*loss_[2, 1]\n",
    "delta_w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = [delta_w1, delta_w2, delta_w3]\n",
    "w_delta_hand = np.zeros([3,2,3])\n",
    "count = 0\n",
    "for w_i in w_list:\n",
    "    w_delta_hand[count] = w_i\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 31.,  51.,  71.],\n",
       "        [ 51.,  71.,  91.]],\n",
       "\n",
       "       [[102., 169., 236.],\n",
       "        [169., 236., 303.]],\n",
       "\n",
       "       [[164., 272., 380.],\n",
       "        [272., 380., 488.]]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_delta_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_delta手計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[125 137]\n",
      "  [102 113]]\n",
      "\n",
      " [[ 93 102]\n",
      "  [ 93 102]]\n",
      "\n",
      " [[102 113]\n",
      "  [ 93 102]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#わかりにくいけどこれでもできる。　\n",
    "delta_x = np.zeros([2,4])\n",
    "\n",
    "x_pre = np.dot(w_.T, loss_)\n",
    "print(x_pre)\n",
    "delta_x[:, 0] = x_pre[0, :, 0]\n",
    "delta_x[:, 1] = x_pre[0, :, 1] + x_pre[1, :, 0]\n",
    "delta_x[:, 2] = x_pre[1, :, 1] + x_pre[2, :, 0]\n",
    "delta_x[:, 3] = x_pre[2, :, 1]\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## これでもできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "left0 = loss_[0,0]*w_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "right0 = loss_[0,1]*w_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1 = loss_[1,0]*w_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "right1 = loss_[1,1]*w_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "left2 = loss_[2,0]*w_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "right2 = loss_[2,1]*w_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_one =left0 + left1 + left2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_one = right0 + right1 + right2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_delta_tryal = np.zeros([2,4])\n",
    "X_delta_tryal[:, 0:3] += left_one\n",
    "X_delta_tryal[:, 1:4] += right_one\n",
    "X_delta_tryal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for分を使って求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])\n",
    "\n",
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "dX = np.zeros(list(x_.shape))\n",
    "dW = np.zeros(list(w_.shape))\n",
    "\n",
    "for k in range(loss_.shape[1]):\n",
    "    for i in range(loss_.shape[0]):\n",
    "        dX[:, k:k+3] +=loss_[i, k]*w_[i]\n",
    "        \n",
    "        dW[i] += loss_[i, k]*x_[:, k:k+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 31.,  51.,  71.],\n",
       "        [ 51.,  71.,  91.]],\n",
       "\n",
       "       [[102., 169., 236.],\n",
       "        [169., 236., 303.]],\n",
       "\n",
       "       [[164., 272., 380.],\n",
       "        [272., 380., 488.]]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数化 backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backword(x, w, dA):\n",
    "    dX = np.zeros(list(x_.shape))\n",
    "    dW = np.zeros(list(w_.shape))\n",
    "    for k in range(loss_.shape[1]):\n",
    "        for i in range(loss_.shape[0]):\n",
    "            dX[:, k:k+3] +=loss_[i, k]*w_[i]\n",
    "            dW[i] += loss_[i, k]*x_[:, k:k+3]\n",
    "            \n",
    "    return dX, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[125., 230., 204., 113.],\n",
       "        [102., 206., 195., 102.]]), array([[[ 31.,  51.,  71.],\n",
       "         [ 51.,  71.,  91.]],\n",
       " \n",
       "        [[102., 169., 236.],\n",
       "         [169., 236., 303.]],\n",
       " \n",
       "        [[164., 272., 380.],\n",
       "         [272., 380., 488.]]]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backword(x_, w_, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch():\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, siguma):\n",
    "        self.siguma = siguma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        self.siguma = np.sqrt(2/n_nodes1)\n",
    "        W = self.siguma*np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        self.siguma = np.sqrt(2/n_nodes2)\n",
    "        B = self.siguma*np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "#         self.h_dW = 0\n",
    "#         self.h_dB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "#         from (zerotuku)\n",
    "#         for key in params.keys():\n",
    "#             self.h[key] += grads[key] * grads[key]\n",
    "#             params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "#         print(layer.dW.shape)\n",
    "\n",
    "        layer.ada_W += layer.dW**2\n",
    "        layer.ada_B += layer.dB**2\n",
    "        \n",
    "        layer.W -= self.lr*layer.dW/(np.sqrt(layer.ada_W) + 1e-7)\n",
    "        layer.B -= (self.lr*layer.dB/(np.sqrt(layer.ada_B) + 1e-7)).mean(0)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.mask = (X <= 0)\n",
    "        out = X.copy()\n",
    "        out[self.mask] = 0\n",
    " \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dX = dout\n",
    "\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_with_Loss:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.forword_A = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.forword_A = np.exp(A)/(np.exp(A).sum(1).reshape(-1, 1))\n",
    "        return self.forword_A\n",
    "\n",
    "    def backward(self, y):\n",
    "\n",
    "        return self.forword_A - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.dB = 0\n",
    "        self.dW = 0\n",
    "        self.ada_W = 0\n",
    "        self.ada_B = 0\n",
    "        self.v_W = 0\n",
    "        self.v_B = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.forward_Z = X.copy()\n",
    "        A = np.dot(X, self.W) + self.B        \n",
    "        \n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        self.dB = dA\n",
    "        self.dW = np.dot(self.forward_Z.T, dA)\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        # 更新\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンボル用クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \n",
    "    def __init__(self, filter_col, initializer, optimizer):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.Filter_col = filter_col\n",
    "        \n",
    "        # 初期化\n",
    "        self.Filter = initializer.Filter(self.Filter_col)\n",
    "        self.Baias = initializer.Bias()\n",
    "        self.dFilter = 0\n",
    "        self.dBaias = 0\n",
    "        self.forward_X = 0\n",
    "        self.ada_Filter = 0\n",
    "        self.ada_Baias = 0\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "\n",
    "#         backwardでもX流用したい\n",
    "        self.forward_X = X.copy()\n",
    "        \n",
    "        sample_num,  X_col = X.shape\n",
    "        \n",
    "#         スライドする回数\n",
    "        slide_col = X_col - self.Filter_col\n",
    "\n",
    "#         fowardで出力　する形状の初期設定（forで計算ごとに値を埋め込んでいきたい）\n",
    "        out_put = np.zeros([sample_num, slide_col])\n",
    "\n",
    "        \n",
    "        for sample in range(sample_num):\n",
    "            for col in range(slide_col):\n",
    "#                 forwardの計算ごとに出力の行列に計算値を埋め込み\n",
    "                a = (X[sample, col : col + self.Filter_col]*self.Filter).sum() + self.Baias[col]\n",
    "                out_put[sample, col] = a\n",
    "\n",
    "        return out_put\n",
    "    def backward(self, dA):\n",
    "        \n",
    "        X = self.forward_X\n",
    "        \n",
    "#         バイアス保持したい最適化関数にしようする\n",
    "        self.dBaias = dA\n",
    "    \n",
    "    #         初期設定\n",
    "        dX = np.zeros(list(X.shape))\n",
    "        dFilter = np.zeros(list(self.Filter.shape))\n",
    "        \n",
    "        dAsample, dAcol = dA.shape\n",
    "        sample_num, X_col = dX.shape\n",
    "        \n",
    "        for sample in range(dAsample):\n",
    "            for col in range(dAcol):\n",
    "#                 dX計算\n",
    "                dX[sample, col:col+self.Filter_col] += dA[sample, col]*self.Filter\n",
    "#                 フィルタは最適化関数　で流用するので保持したい\n",
    "                self.dFilter += dA[sample, col]*X[sample, col:col+self.Filter_col]\n",
    "    \n",
    "#     最適化　する\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_He:\n",
    "    \"\"\"\n",
    "   コンブ用He\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "        \n",
    "    def Filter(filter_col):\n",
    "        \"\"\"\n",
    "        フィルターの初期化\n",
    "        Parameters\n",
    "        \"\"\"\n",
    "        siguma = np.sqrt(2/filter_col)\n",
    "        filter = siguma*np.random.randn(filter_col)\n",
    "        \n",
    "        return filter\n",
    "    \n",
    "    def Bias():\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        \"\"\"\n",
    "        siguma = np.sqrt(2/600)\n",
    "        B = siguma*np.random.randn(600)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad_for_conv:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        pass\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        layer.ada_Filter += layer.dFilter**2\n",
    "        layer.ada_Baias += layer.dBaias**2\n",
    "        \n",
    "        layer.Filter -= self.lr*layer.dFilter/(np.sqrt(layer.ada_Filter) + 1e-7)\n",
    "        layer.Baias -= (self.lr*layer.dBaias/(np.sqrt(layer.ada_Baias) + 1e-7)).mean(0)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier_add_conv:\n",
    "\n",
    "        def __init__(self, verbose = True, epoch = 0 , alpha = 0.01, activater = Relu,  initializer = He, optimizer = AdaGrad, filter_col = 184):\n",
    "            self.verbose = verbose\n",
    "            self.n_features = 784\n",
    "            self.filter_col = filter_col\n",
    "            \n",
    "#             コンボルあとのノード数\n",
    "            self.n_nodes1 = self.n_features - self.filter_col\n",
    "            self.n_nodes2 = 200\n",
    "            self.n_output = 10\n",
    "            self.sigma = 0.01   # ガウス分布の標準偏差\n",
    "            self.batch_size=10\n",
    "            self.loss_box = []\n",
    "            self.epoch = epoch\n",
    "            self.lr = alpha\n",
    "            self.activater = activater\n",
    "            self.initializer = initializer\n",
    "            self.optimizer = optimizer\n",
    "            \n",
    "            #             コンボル用に追加したクラス\n",
    "            self.conv_initializer = Conv_He\n",
    "            self.optimizer_conv = AdaGrad_for_conv\n",
    "            \n",
    "            pass\n",
    "\n",
    "        def fit(self, X, y, X_val=None, y_val=None):\n",
    "\n",
    "            \"\"\"\n",
    "            初期値\n",
    "            \"\"\"\n",
    "            # self.sigma : ガウス分布の標準偏差\n",
    "            # self.lr : 学習率\n",
    "            # self.n_nodes1 : 1層目のノード数\n",
    "            # self.n_nodes2 : 2層目のノード数self, filter_col, initializer, optimizer\n",
    "            # self.n_output : 出力層のノード数\n",
    "            \n",
    "#             コンボル層\n",
    "            self.FC1 = Conv1d(self.filter_col, self.conv_initializer, self.optimizer_conv(self.lr))\n",
    "            self.activation1 = self.activater()\n",
    "            \n",
    "            self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "            self.activation2 = self.activater()\n",
    "            self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "            self.activation3 = Softmax_with_Loss()\n",
    "            \"\"\"Get_mini_batch\"\"\"\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
    "\n",
    "            \"\"\"エポック回イテレート\"\"\"\n",
    "            for i in range(self.epoch):\n",
    "                for mini_X_train, mini_y_train in get_mini_batch:\n",
    "\n",
    "                    \"\"\"\n",
    "                    Forword\n",
    "                    \"\"\"\n",
    "                    A1 = self.FC1.forward(mini_X_train)\n",
    "                    Z1 = self.activation1.forward(A1)\n",
    "                    A2 = self.FC2.forward(Z1)\n",
    "                    Z2 = self.activation2.forward(A2)\n",
    "                    A3 = self.FC3.forward(Z2)\n",
    "                    Z3 = self.activation3.forward(A3)\n",
    "                    \"\"\"\n",
    "                    Backword\n",
    "                    \"\"\"\n",
    "                    dA3 = self.activation3.backward(mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせてい\n",
    "                    dZ2 = self.FC3.backward(dA3)\n",
    "                    dA2 = self.activation2.backward(dZ2)\n",
    "                    dZ1 = self.FC2.backward(dA2)\n",
    "                    dA1 = self.activation1.backward(dZ1)\n",
    "                    dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "                  \n",
    "                \"\"\"\n",
    "                Forword  after optimized weight\n",
    "                \"\"\"\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                print('__{}TIMES　of epoch__'.format(i+1))\n",
    "                print('L0SS={}'.format(self.cross_entropy_loss(Z3, y)))\n",
    "                print('ACCURACY_SCORE={}'.format(accuracy_score(y.argmax(1), Z3.argmax(1))))\n",
    "                \n",
    "                self.loss_box.append(self.cross_entropy_loss(Z3, y))\n",
    "\n",
    "            if self.verbose:\n",
    "                print()\n",
    "                #verboseをTrueにした際は学習過程などを出力する\n",
    "            return self.loss_box\n",
    "\n",
    "        def cross_entropy_loss(self, final_Z, y):\n",
    "            l =  -y*(np.log(final_Z))/self.batch_size\n",
    "            L = l.sum()\n",
    "            return L\n",
    "\n",
    "        def predict(self, X):\n",
    "            \"\"\"\n",
    "            Forword action after optimized weight\n",
    "            \"\"\"\n",
    "            A1 = self.FC1.forward(X)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "\n",
    "            return Z3.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_conv1 = ScratchSimpleNeuralNetrowkClassifier_add_conv(epoch = 3 , alpha = 0.01, activater = Relu,  initializer = He, optimizer = AdaGrad, filter_col = 184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__1TIMES　of epoch__\n",
      "L0SS=99.43174271014956\n",
      "ACCURACY_SCORE=0.92025\n",
      "__2TIMES　of epoch__\n",
      "L0SS=41.42596525869554\n",
      "ACCURACY_SCORE=0.969\n",
      "__3TIMES　of epoch__\n",
      "L0SS=18.101265642743655\n",
      "ACCURACY_SCORE=0.986\n",
      "\n",
      "0.93\n",
      "4min 23s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r １ -n 1\n",
    "\n",
    "loss_box_Tanh = nn_conv1.fit(X_train[:4000], y_train[:4000])\n",
    "\n",
    "y_pred = nn_conv1.predict(X_val)\n",
    "\n",
    "print(accuracy_score(y_val.argmax(1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### かなり時間　がかかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
