{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 1, 28, 28))\n",
    "X_test = X_test.reshape((10000, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 28, 28)\n",
      "(12000, 1, 28, 28)\n",
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #  Sammary  Forward\n",
    "        #  -----------------------------------------------------------------------------------------------------------------\n",
    "        #  Layer (type)                       Input Shape                     Filter Shape             Output Shape   \n",
    "        #  ================================================================\n",
    "        #  conv2d_1 (Conv2D)       (sample, 1, 28, 28)         ( 32,1, 2, 2)         (sample, 32, 26, 26)     \n",
    "        #  ________________________________________________________________\n",
    "        #  maxpooling2d_1 \n",
    "        #  (MaxPooling2D)             (sample, 32, 26, 26)            ( 2, 2)                (sample, 32, 13, 13)\n",
    "        #  ________________________________________________________________\n",
    "        #  conv2d_2 (Conv2D)    (sample, 32, 13, 13)        (64, 32, 2, 2)       (sample, 64, 11, 11)\n",
    "        #  ________________________________________________________________\n",
    "        #  maxpooling2d_2 \n",
    "        #  (MaxPooling2D)            (sample, 64, 11, 11)           ( 2, 2)                (sample, 64, 5, 5)\n",
    "        #  ________________________________________________________________\n",
    "        #  conv2d_3 (Conv2D)    (sample, 64, 5, 5)         ( 64, 64, 2, 2)          (sample,64,  3, 3)                                                    \n",
    "        #  ________________________________________________________________\n",
    "        #  flatten_1 (Flatten)      (sample,64,  3, 3)                                              (sample, 576)\n",
    "        #  ________________________________________________________________\n",
    "        #  dense_1 (Dense)          (sample, 576)                                                     (sample, 64)\n",
    "        #  ________________________________________________________________\n",
    "        #  dense_2 (Dense)         (sample, 64)                                                        (sample, 10)\n",
    "        #  ================================================================                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch():\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, siguma):\n",
    "        self.siguma = siguma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        H_siguma = np.sqrt(2/n_nodes1)\n",
    "        W = H_siguma*np.random.randn(n_nodes1, n_nodes2)\n",
    "\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        H_siguma = np.sqrt(2/n_nodes2)\n",
    "        B = H_siguma*np.random.randn(n_nodes2)\n",
    "#         print('B'+str(B.shape))\n",
    "\n",
    "        return B\n",
    "\n",
    "    def filter(self, filter_info):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        filter_num, filter_chan, filter_row, filter_col = filter_info\n",
    "\n",
    "        H_siguma = np.sqrt(2/filter_num)\n",
    "        filter = H_siguma*np.random.randn(filter_num, filter_chan, filter_row, filter_col)\n",
    "        \n",
    "        return filter\n",
    "\n",
    "    def bias(self,  filter_num):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        H_siguma = np.sqrt(2/filter_num)\n",
    "        bias = H_siguma*np.random.randn(filter_num)\n",
    "#         print('bias' + str(bias.shape))\n",
    "\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, type = 'all_conect'):\n",
    "        self.lr = lr\n",
    "        self.type = type\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "#         from (zerotuku)\n",
    "#         for key in params.keys():\n",
    "#             self.h[key] += grads[key] * grads[key]\n",
    "#             params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "#         print(layer.dW.shape)\n",
    "\n",
    "        # 全結合層用\n",
    "        if self.type == 'all_conect':\n",
    "            layer.ada_W += layer.dW**2\n",
    "            layer.ada_B += layer.dB**2\n",
    "\n",
    "            layer.W -= self.lr*layer.dW/(np.sqrt(layer.ada_W) + 1e-7)\n",
    "            layer.B -= (self.lr*layer.dB/(np.sqrt(layer.ada_B) + 1e-7)).mean(0)\n",
    "#             print('layer.B'+ str(layer.B.shape))\n",
    "\n",
    "        # コンボル層更新用\n",
    "        if self.type == 'conv':\n",
    "            layer.ada_filter += layer.dfilter**2\n",
    "            layer.ada_bias += layer.dbias**2\n",
    "            \n",
    "#             j = (self.lr*layer.dbias/(np.sqrt(layer.ada_bias) + 1e-7))\n",
    "#             print(j.shape)\n",
    "\n",
    "# #             print用\n",
    "            j = (self.lr*layer.dbias/(np.sqrt(layer.ada_bias) + 1e-7))\n",
    "#             print('layer.bias_pre'+ str(j.shape))\n",
    "            \n",
    "            layer.filter -= self.lr*layer.dfilter/(np.sqrt(layer.ada_filter) + 1e-7)\n",
    "            layer.bias -= (self.lr*layer.dbias/(np.sqrt(layer.ada_bias) + 1e-7)).mean(-1).mean(-1).mean(0)\n",
    "#             print('layer.bias_pre'+ str(self.lr*layer.dbias/(np.sqrt(layer.ada_bias) + 1e-7)).mean(1).mean(1))\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.mask = (X <= 0)\n",
    "        out = X.copy()\n",
    "        out[self.mask] = 0\n",
    " \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dX = dout\n",
    "\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_with_Loss:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.forword_A = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.forword_A = np.exp(A)/(np.exp(A).sum(1).reshape(-1, 1))\n",
    "        return self.forword_A\n",
    "\n",
    "    def backward(self, y):\n",
    "\n",
    "        return self.forword_A - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forword and Backword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.dB = 0\n",
    "        self.dW = 0\n",
    "        self.ada_W = 0\n",
    "        self.ada_B = 0\n",
    "        self.v_W = 0\n",
    "        self.v_B = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.forward_Z = X.copy()\n",
    "        A = np.dot(X, self.W) + self.B        \n",
    "        \n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        self.dB = dA\n",
    "        self.dW = np.dot(self.forward_Z.T, dA)\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        # 更新\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, filter_info, initializer, optimizer, shapetype = None):\n",
    "        self.optimizer = optimizer\n",
    "        self.filter_num, self.filter_kernel, self.filter_row, self.filter_col = filter_info\n",
    "        self.shapetype = shapetype\n",
    "\n",
    "        self.filter = initializer.filter(filter_info)\n",
    "        self.bias = initializer.bias(self.filter_num)\n",
    "        self.ada_filter = 0\n",
    "        self.dfilter = 0\n",
    "        self.ada_bias =0\n",
    "        self.dbias = 0\n",
    "\n",
    "\n",
    "        # filter = np.ones([self.filter_num, self.filter_row, self.filter_col, channel_num])\n",
    "        # bias = np.ones([self.filter_num, 1, 1])\n",
    "        # self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        # self.B = initializer.B(n_nodes2)\n",
    "    \n",
    "    def forward( self, input):\n",
    "\n",
    "        self.forward_input = input.copy()\n",
    "\n",
    "        #最初だけ型が違うから。\n",
    "        # if self.shapetype == 'first':\n",
    "        #     print('first')\n",
    "        #     sample_num, input_row, input_col, channel_num = input.shape\n",
    "            \n",
    "        \n",
    "#         print('second')\n",
    "        sample_num, input_channel, input_row, input_col = input.shape\n",
    "\n",
    "        slide_row = input_row - self.filter_row\n",
    "        slide_col = input_col - self.filter_col\n",
    "\n",
    "        # if self.shapetype == 'first':\n",
    "        #     #出力の形状設定\n",
    "        #     out_put = np.zeros([sample_num, self.filter_num, slide_row, slide_col])\n",
    "        #     for sample in range(sample_num):\n",
    "        #         for filter_n in range(self.filter_num):\n",
    "        #             for row in range(slide_row):\n",
    "        #                 for col in range(slide_col):\n",
    "        #                     a = (input[sample, row : row + self.filter_row, col : col + self.filter_col]*self.filter[filter_n]).sum() + self.bias[filter_n]\n",
    "        #                     out_put[sample, filter_n, row, col] = a \n",
    "                        \n",
    "    # else:\n",
    "        #出力の形状設定\n",
    "        out_put = np.zeros([sample_num, self.filter_num, slide_row, slide_col])\n",
    "        for sample in range(sample_num):\n",
    "            for input_chan in range(input_channel):\n",
    "                for filter_n in range(self.filter_num):\n",
    "                    for row in range(slide_row):\n",
    "                        for col in range(slide_col):\n",
    "                            a = (input[sample, input_chan, row : row + self.filter_row, col : col + self.filter_col]*self.filter[filter_n]).sum() + self.bias[filter_n]\n",
    "                            out_put[sample, filter_n, row, col] = a\n",
    "                        \n",
    "        return out_put\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \n",
    "        self.dbias = dA\n",
    "        dX = np.zeros(list(self.forward_input.shape))\n",
    "        self.dfilter = np.zeros(list(self.filter.shape))\n",
    "\n",
    "        sample_inp,chan_inp , row_inp, col_inp = self.forward_input.shape\n",
    "\n",
    "        filter_num, filter_chan, filter_row, filter_col = self.filter.shape\n",
    "\n",
    "        dAsample, dAchanel, dArow, dAcol = dA.shape\n",
    "        # print(self.filter.shape)\n",
    "        # print(filter_row, filter_col)\n",
    "\n",
    "        for sample in range(dAsample):\n",
    "            for i_chan in range(chan_inp):\n",
    "                for chanel_n in range(dAchanel):\n",
    "                    for row in range(dArow):\n",
    "                        for col in range(dAcol):\n",
    "                            # print(dX[sample, row:row+filter_row, col:col+filter_col])\n",
    "                            # print(dA[sample, chanel_n, row, col]\n",
    "                            # print(self.filter[chanel_n])\n",
    "                            # print(dX[sample, row:row+filter_row, col:col+filter_col].shape)\n",
    "                            # print(dA[sample, chanel_n, row, col].shape)\n",
    "                            # print(self.filter[chanel_n].shape)\n",
    "\n",
    "                            dX[sample,i_chan, row:row+filter_row, col:col+filter_col] += dA[sample, chanel_n, row, col]*self.filter[chanel_n, i_chan]\n",
    "                            self.dfilter[chanel_n,i_chan] += dA[sample, chanel_n, row, col]*self.forward_input[sample, i_chan, row:row+filter_row, col:col+filter_col]\n",
    "\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max_Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pooling:\n",
    "    def __init__(self, shape = (2, 2)):\n",
    "        self.filter_row, self.filter_col = shape\n",
    "        self.max_index = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Max_pool\n",
    "        # X.sahpe (5, 32, 3, 3)\n",
    "        # (X_sample, filter_num, filter_row, filter_col)\n",
    "\n",
    "        input_sample, input_fillnum, input_row, input_col = X.shape\n",
    "        self.foward_X = X\n",
    "#         print(input_row)\n",
    "#         print(self.filter_row)\n",
    "\n",
    "        if input_row%self.filter_row != 0:\n",
    "            input_row = input_row - (input_row%self.filter_row)\n",
    "            input_col = input_col - (input_col%self.filter_col)\n",
    "\n",
    "        slide_row = int(input_row/self.filter_row)\n",
    "        slide_col = int(input_col/self.filter_col)\n",
    "        self.max_index = []\n",
    "\n",
    "        out_put = np.zeros([input_sample, input_fillnum, slide_row, slide_col])\n",
    "\n",
    "        for sample_n in range(input_sample):\n",
    "            for filter_n in range(input_fillnum):\n",
    "                for row in range(slide_row):\n",
    "                    for col in range(slide_col):\n",
    "                        \n",
    "                        X_where = X[sample_n,  filter_n, (row*self.filter_row):(row*self.filter_row)+self.filter_row, (col*self.filter_col):(col*self.filter_col)+self.filter_col]\n",
    "                        index = np.unravel_index(np.argmax(X_where, axis=None), X_where.shape)\n",
    "                        X_max_index = [sample_n,  filter_n, (row*self.filter_row)+index[0], (col*self.filter_col)+index[1]]\n",
    "#                         print('max_index{}'.format(np.array(index)))\n",
    "                        self.max_index.append(X_max_index)\n",
    "                        out_put[sample_n, filter_n, row, col] = X_where.max()\n",
    "        \n",
    "        return out_put\n",
    "    \n",
    "    def backward(self, A):\n",
    "        # Max_pool　　back\n",
    "#         (5, 32, 13, 13)から\n",
    "#         元のshape(5, 32, 26, 26)へ戻す\n",
    "\n",
    "        loss_sample, loss_fillnum, loss_row, loss_col = A.shape\n",
    "        loss_1darray = A.ravel()\n",
    "        foward_sample, foward_channel, foward_row, foward_col = self.foward_X.shape\n",
    "        \n",
    "#         new_row, new_col = loss_row*self.filter_row, loss_col*self.filter_col\n",
    "\n",
    "        out_put = np.zeros([loss_sample, loss_fillnum, foward_row, foward_col])\n",
    "#         print(len(self.max_index))\n",
    "\n",
    "#         for sample_n in range(loss_sample):\n",
    "#             for filter_n in range(loss_fillnum):\n",
    "        for index in range(len(self.max_index)):\n",
    "            index_row = self.max_index[index]\n",
    "            out_put[index_row[0], index_row[1], index_row[2], index_row[3]] = loss_1darray[index]\n",
    "                    \n",
    "        return out_put"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。  \n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。  \n",
    "その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。  \n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self,):\n",
    "        \n",
    "        self.row = 0\n",
    "        self.col = 0\n",
    "        self.sample =0\n",
    "        self.filnum =0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Flatten to X\n",
    "        \n",
    "        self.sample, self.filnum, self.row , self.col = X.shape\n",
    "        \n",
    "        flat = X.reshape(self.sample, -1)\n",
    "        \n",
    "        return flat\n",
    "    def backward(self, dA):\n",
    "        # back to original shape\n",
    "        \n",
    "        out_put = dA.reshape(self.sample, self.filnum, self.row , self.col)\n",
    "        \n",
    "        return out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier_add_conv:\n",
    "    \n",
    "    def __init__(self, verbose = True, epoch = 0, alpha = 0.01, activater = Relu,  initializer = He, optimizer = AdaGrad):\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "            #    全結合ノード数\n",
    "        self.n_nodes1 = 576\n",
    "        self.n_nodes2 = 64\n",
    "        self.n_output = 10\n",
    "        \n",
    "        self.sigma = 0.01\n",
    "        self.batch_size=10\n",
    "        self.loss_box = []\n",
    "        self.epoch = epoch\n",
    "        self.lr = alpha\n",
    "        \n",
    "                #  filter.shape\n",
    "        self.filter1 = ( 32,1, 2, 2)\n",
    "        self.filter2 = (64, 32, 2, 2)\n",
    "        self.filter3 = ( 64, 64, 2, 2)\n",
    "        \n",
    "                #  players\n",
    "        self.activater = activater\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        初期値\n",
    "        \"\"\"\n",
    "        #  self.sigma : ガウス分布の標準偏差\n",
    "        #  self.lr : 学\n",
    "        #  self.n_nodes1 : #1層目のノード数\n",
    "        #  self.n_nodes2 : #2層目のノード数\n",
    "        #  self.n_output : 出力層のノード数\n",
    "\n",
    "        #  Sammary  Forward\n",
    "        #  -----------------------------------------------------------------------------------------------------------------\n",
    "        #  Layer (type)                       Input Shape                     Filter Shape             Output Shape   \n",
    "        #  ================================================================\n",
    "        #  conv2d_1 (Conv2D)       (sample, 1, 28, 28)         ( 32,1, 2, 2)         (sample, 32, 26, 26)     \n",
    "        #  ________________________________________________________________\n",
    "        #  maxpooling2d_1 \n",
    "        #  (MaxPooling2D)             (sample, 32, 26, 26)            ( 2, 2)                (sample, 32, 13, 13)\n",
    "        #  ________________________________________________________________\n",
    "        #  conv2d_2 (Conv2D)    (sample, 32, 13, 13)        (64, 32, 2, 2)       (sample, 64, 11, 11)\n",
    "        #  ________________________________________________________________\n",
    "        #  maxpooling2d_2 \n",
    "        #  (MaxPooling2D)            (sample, 64, 11, 11)           ( 2, 2)                (sample, 64, 5, 5)\n",
    "        #  ________________________________________________________________\n",
    "        #  conv2d_3 (Conv2D)    (sample, 64, 5, 5)         ( 64, 64, 2, 2)          (sample,64,  3, 3)                                                    \n",
    "        #  ________________________________________________________________\n",
    "        #  flatten_1 (Flatten)      (sample,64,  3, 3)                                              (sample, 576)\n",
    "        #  ________________________________________________________________\n",
    "        #  dense_1 (Dense)          (sample, 576)                                                     (sample, 64)\n",
    "        #  ________________________________________________________________\n",
    "        #  dense_2 (Dense)         (sample, 64)                                                        (sample, 10)\n",
    "        #  ================================================================\n",
    "            \n",
    "\n",
    "         #コンボル層\n",
    "                    # 1層\n",
    "        self.Conv2d_1 = Conv2d(self.filter1, self.initializer(self.sigma), self.optimizer(self.lr, type = 'conv'), shapetype = 'first')\n",
    "        self.activation1 = self.activater()\n",
    "        self.Max1 = Max_Pooling()\n",
    "                    # 2層\n",
    "        self.Conv2d_2 = Conv2d(self.filter2, self.initializer(self.sigma), self.optimizer(self.lr, type = 'conv'))\n",
    "        self.activation2 = self.activater()\n",
    "        self.Max2 = Max_Pooling()\n",
    "                #    3層\n",
    "        self.Conv2d_3 = Conv2d(self.filter3, self.initializer(self.sigma), self.optimizer(self.lr, type = 'conv'))\n",
    "        self.activation3 = self.activater()\n",
    "        self.Flat = Flatten()\n",
    "        \n",
    "                  #全結合層\n",
    "                #   4層\n",
    "        self.FC4 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), self.optimizer(self.lr, type = 'all_conect'))\n",
    "        self.activation4 = self.activater()\n",
    "                #   5層\n",
    "        self.FC5 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), self.optimizer(self.lr, type = 'all_conect'))\n",
    "        self.activation5 = Softmax_with_Loss()\n",
    "        \n",
    "        \"\"\"Get_mini_batch\"\"\"\n",
    "        get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
    "\n",
    "        \"\"\"エポック回イテレート\"\"\"\n",
    "        for i in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "\n",
    "                \"\"\"\n",
    "                Forword\n",
    "                \"\"\"\n",
    "                A1 = self.Conv2d_1.forward( mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                M1 = self.Max1.forward(Z1)\n",
    "#                 print(M1.shape)\n",
    "                \n",
    "                A2 = self.Conv2d_2.forward(M1)\n",
    "#                 print('conv2'+str(A2.shape))\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                M2 = self.Max2.forward(Z2)\n",
    "                \n",
    "                A3 = self.Conv2d_3.forward(M2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "#                 print(Z3.shape)\n",
    "                FL = self.Flat.forward(Z3)\n",
    "#                 print(FL.shape)\n",
    "        \n",
    "                A4 = self.FC4.forward(FL)\n",
    "                Z4 = self.activation4.forward(A4)\n",
    "                \n",
    "                A5 = self.FC5.forward(Z4)\n",
    "                Z5 = self.activation5.forward(A5)\n",
    "                \n",
    "                \"\"\"\n",
    "                Backword\n",
    "                \"\"\"\n",
    "#                 print('start_backward')\n",
    "                dA5 = self.activation5.backward(mini_y_train)\n",
    "                dZ5 = self.FC5.backward(dA5)\n",
    "                \n",
    "                dA4 = self.activation4.backward(dZ5)\n",
    "                dZ4 = self.FC4.backward(dA4)\n",
    "                \n",
    "                dFL = self.Flat.backward(dZ4)\n",
    "                dZ3 = self.activation3.backward(dFL)\n",
    "#                 print(dZ3.shape)\n",
    "                dA3 = self.Conv2d_3.backward(dZ3)\n",
    "                \n",
    "                dM2 = self.Max2.backward(dA3)\n",
    "#                 print(dM2.shape)\n",
    "                dZ2 = self.activation2.backward(dM2)\n",
    "                dA2 = self.Conv2d_2.backward(dZ2)\n",
    "\n",
    "                dM1 = self.Max1.backward(dA2)\n",
    "                dZ1 = self.activation1.backward(dM1)\n",
    "                dA1 = self.Conv2d_1.backward(dZ1)\n",
    "\n",
    "            \"\"\"\n",
    "            Forword  after optimized weight\n",
    "            \"\"\"\n",
    "            A1 = self.Conv2d_1.forward(X)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            M1 = self.Max1.forward(Z1)\n",
    "            \n",
    "            A2 = self.Conv2d_2.forward(M1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            M2 = self.Max2.forward(Z2)\n",
    "            \n",
    "            A3 = self.Conv2d_3.forward(M2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            FL = self.Flat.forward(Z3)\n",
    "    \n",
    "            A4 = self.FC4.forward(FL)\n",
    "            Z4 = self.activation4.forward(A4)\n",
    "            \n",
    "            A5 = self.FC5.forward(Z4)\n",
    "            Z5 =  self.activation5.forward(A5)\n",
    "\n",
    "            self.loss_box.append(self.cross_entropy_loss(Z5, y))\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation\n",
    "            \"\"\"\n",
    "            if self.verbose:\n",
    "                        #verboseをTrueにした際は学習過程などを出力する\n",
    "                print('__{}TIMES　of epoch__'.format(i+1))\n",
    "                print('L0SS={}'.format(self.cross_entropy_loss(Z5, y)))\n",
    "                print('ACCURACY_SCORE={}'.format(accuracy_score(y.argmax(1), Z5.argmax(1))))\n",
    "\n",
    "        return self.loss_box\n",
    "    \n",
    "    def cross_entropy_loss(self, final_Z, y):\n",
    "        l =  -y*(np.log(final_Z))/self.batch_size\n",
    "        L = l.sum()\n",
    "        return L\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        A1 = self.Conv2d_1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        M1 = self.Max1.forward(Z1)\n",
    "\n",
    "        A2 = self.Conv2d_2.forward(M1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        M2 = self.Max2.forward(Z2)\n",
    "\n",
    "        A3 = self.Conv2d_3.forward(M2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        FL = self.Flat.forward(Z3)\n",
    "\n",
    "        A4 = self.FC4.forward(FL)\n",
    "        Z4 = self.activation4.forward(A4)\n",
    "\n",
    "        A5 = self.FC5.forward(Z4)\n",
    "        Z5 = self.activation5.forward(A5)\n",
    "        \n",
    "        return Z5.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn =  ScratchSimpleNeuralNetrowkClassifier_add_conv(verbose = True, epoch = 3,\n",
    "                            alpha = 0.01, activater = Relu,  initializer = He, optimizer = AdaGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__1TIMES　of epoch__\n",
      "L0SS=2.038027042184431\n",
      "ACCURACY_SCORE=0.3\n",
      "__2TIMES　of epoch__\n",
      "L0SS=1.5449450185626392\n",
      "ACCURACY_SCORE=0.4\n",
      "__3TIMES　of epoch__\n",
      "L0SS=1.6384806103285392\n",
      "ACCURACY_SCORE=0.6\n"
     ]
    }
   ],
   "source": [
    "loss_box = conv_nn.fit(X_train[:10], y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = conv_nn.predict(X_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val[:10].argmax(1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wUdf7H8dcnCaGnhx5IQu+kSGxYzobiiV0Ufnd63HlgwXJ6p+fvmp6np3cWRPG8O/WnIPZez44NMEAo0sRQBWmhIy18f3/shIshCQvJ7uxm38/HYx/s7szsvBmG+ezO7H6+5pxDRERiV5zfAURExF8qBCIiMU6FQEQkxqkQiIjEOBUCEZEYl+B3gEOVkZHhsrOz/Y4hIhJVpk+fvt45l1ndtKgrBNnZ2RQXF/sdQ0QkqpjZspqm6dSQiEiMUyEQEYlxKgQiIjFOhUBEJMapEIiIxDgVAhGRGKdCICIS42KmEGzduYeHPlrMvn1quy0iUlnMFIJ3563hrrcXMu7DxX5HERGJKDFTCM7Ja885ee25971FfPL1Or/jiIhEjJgpBGbG7ef0oWurFoyZNJNVm773O5KISESImUIA0CwxgfEjCthT7rhi4gx2793ndyQREd/FVCEA6JzZgrvO70fJik385c35fscREfFdzBUCgDP6tmXksTk8/vlSXp21yu84IiK+islCAHDT6T0o7JTKTS/MZvHarX7HERHxTcwWgkbxcYy7JJ9mifGMmjCD7bv2+h1JRMQXMVsIANokN2HssDxK123j5hfn4Jx+bCYisSemCwHA0V0y+NWp3Xl11iqenFLjAD4iIg1WzBcCgNHHd+akHq247fV5zFy+0e84IiJhpUIAxMUZ91w4gNZJTbhy4gzKtu/2O5KISNiErBCYWZaZfWhm883sKzO7ppp5zMzGmtliM5ttZvmhynMwyc0aMX54Aeu37ebaZ0ooV3M6EYkRofxEsBf4lXOuJ3AkcKWZ9aoyz+lAV+92OTA+hHkOqm+HZP54Vm8mL1rHAx987WcUEZGwCVkhcM6tds7N8O5vBeYD7avMNhR4wgVMAVLMrG2oMgXj4oFZnJvfnvvf/5qPFq71M4qISFiE5RqBmWUDecDUKpPaAysqPV7JgcUirMyM28/uS/fWLbn2mRK+VXM6EWngQl4IzKwF8AJwrXNuS9XJ1SxywMl5M7vczIrNrHjdutC3kG6aGM/4EQWUe83pdu0tD/k6RUT8EtJCYGaNCBSBic65F6uZZSWQVelxB+CA5j/OuUecc4XOucLMzMzQhK0iJ6M5d1/Qj1krNnH7G2pOJyINVyi/NWTAv4H5zrl7apjtVeAn3reHjgQ2O+dWhyrToRrcpy2/GJTDE18s45WSb/2OIyISEgkhfO1jgP8B5phZiffcb4GOAM65h4E3gTOAxcAO4LIQ5jksvx7cg5IVm7jphTn0aptE19Yt/Y4kIlKvLNr66xQWFrri4uKwrnPNlp0MGfspyU0TeOWqY2nROJT1U0Sk/pnZdOdcYXXT9MviILROasIDF+exZP12bnphtprTiUiDokIQpKM6p3PDad15ffZq/u/zpX7HERGpNyoEh2DUcZ05uWcrbn9zPjPUnE5EGggVgkMQF2f8/YIBtEkONKfbsG2X35FEROpMheAQVTSn27B9N9c8reZ0IhL9VAgOQ5/2ydx6Vm8+Xbye+99b5HccEZE6USE4TBcdkcX5BR0Y+8FiPlRzOhGJYioEh8nMuG1oH3q2TeK6Z0pYuXGH35FERA6LCkEdNE2MZ/zwfDWnE5GopkJQR9kZzfnbhf2ZvXIzt70+z+84IiKHTIWgHpzWuw2/PC6XCVOW8/JMNacTkeiiQlBPbjytOwNz0rj5xTksWrPV7zgiIkFTIagnCfFxjLs4j+aNExg1YTrbdu31O5KISFBUCOpRq6QmjLskj2UbdvCb59WcTkSigwpBPTsyN50bT+vOG3NW89hnS/2OIyJyUCoEIfDL43I5pVdr/vLmfKYvK/M7johIrVQIQsDM+NsF/Wmf2pQrJs5gvZrTiUgEUyEIkeSmjXhoeD6bduzhmqdnqjmdiEQsFYIQ6t0umduG9uGzxRu49101pxORyKRCEGIXHpHFRYVZjPtwMR8sWON3HBGRA6gQhMGfhvamV9skrntmFivK1JxORCKLCkEYNGkUz8MjCtjnAs3pdu5RczoRiRwqBGHSMb0Z91w4gDnfbuZWNacTkQiiQhBGp/RqzajjO/PU1OW8OGOl33FERAAVgrC74dRuHJmbxm9fmsOC77b4HUdERIUg3BLi4xh7cR5JTRoxesIMtu7c43ckEYlxKgQ+aNWyCeMuyWd52Q5+reZ0IuIzFQKfDMxJ4zeDu/PW3O/496dL/I4jIjFMhcBHvxiUy2m9W3PHWwv4cqma04mIP1QIfGRm3H1Bf7JSm3LlxBms26rmdCISfioEPktq0oiHhhew+fs9jJk0k73l+/yOJCIxJmSFwMweNbO1Zja3humpZvaSmc02s2lm1idUWSJdr3ZJ/PnsPnxRuoF71JxORMIslJ8IHgcG1zL9t0CJc64f8BPg/hBmiXgXFGZx8cAsHvroG96bp+Z0IhI+ISsEzrnJQG1XQHsB73vzLgCyzax1qPJEgz/8uDd92idx/bMlLN+g5nQiEh5+XiOYBZwLYGYDgU5ABx/z+K5Jo3jGDy8A4Iqnpqs5nYiEhZ+F4E4g1cxKgKuBmcDe6mY0s8vNrNjMitetWxfOjGGXldaMey8awNxvt/Cn177yO46IxADfCoFzbotz7jLn3AAC1wgygWp/WeWce8Q5V+icK8zMzAxrTj+c1LM1V5zQmUnTVvD8dDWnE5HQ8q0QmFmKmSV6D38OTHbOqQub5/pTunFUbjq3vDSH+au1WUQkdEL59dFJwBdAdzNbaWYjzWyUmY3yZukJfGVmC4DTgWtClSUaVTSnS27aiNETprNFzelEJEQs2hqeFRYWuuLiYr9jhM2XS8sY9sgUTu7ZiodHFGBmfkcSkShkZtOdc4XVTdMviyPcEdlp3Hx6D975ag3//KTU7zgi0gCpEESBkcfmcHqfNvz17YVMLd3gdxwRaWBUCKKAmXHX+f3omNaMqybNZO3WnX5HEpEGRIUgSrRs0ojxI/LZunMPVz+l5nQiUn9UCKJIjzZJ/OWcvkxdUsbf/qPmdCJSP1QIosy5+R24pKgjD3/8De+qOZ2I1AMVgij0+zN70bd9Mtc/W8KyDdv9jiMiUU6FIAo1aRTPQ8PziTNj9IQZak4nInWiQhClAs3p+jNv9Rb+8Iqa04nI4VMhiGI/6tGaq07swjPFK3i2eIXfcUQkSqkQRLnrTunGMV3S+d3Lc/lq1Wa/44hIFFIhiHLxccb9w/JIbZbI6Akz2Py9mtOJyKFRIWgAMlo05sHheaza9D03PDeLaGskKCL+UiFoIAo6pXHzGT15d94a/jFZzelEJHgqBA3Iz47JZkjfttz19gKmqDmdiARJhaABMTPuPK8v2enNueqpmazdouZ0InJwKgQNTKA5XQHbd+3lqklqTiciB6dC0AB1b9OSO87ty7QlZdz9zkK/44hIhFMhaKDOzmvPiCM78o/Jpbzz1Xd+xxGRCKZC0ID97sxe9O+QzA3PzmLpejWnE5HqqRA0YI0T4nlweD7x8cboiWpOJyLVUyFo4DqkNuPeiwaw4Lst/O7luX7HEZEIpEIQA07s3oqrT+zCc9NX8syXy/2OIyIRRoUgRlxzcjcGdc3gd698xdxv1ZxORP5LhSBGxMcZ9100gPTmiYyeOJ3NO9ScTkQCVAhiSHqLxoy7JJ/Vm3byq+dK2LdPzelERIUg5hR0SuWWIT15b/5aHp78jd9xRCQCqBDEoEuPzmZIv7b87Z2FfP7Ner/jiIjPVAhikJnx1/P6kZPRnDGTZrJGzelEYpoKQYxq0TiBh0cUsGN3OVc9NYM9ak4nErOCKgRm1tnMGnv3TzCzMWaWEtpoEmpdWwea0325dCN3vb3A7zgi4pNgPxG8AJSbWRfg30AO8FTIUknYDB3Qnp8c1Yl/frKEt+eu9juOiPgg2EKwzzm3FzgHuM85dx3QtrYFzOxRM1trZtX2NTCzZDN7zcxmmdlXZnbZoUWX+nLLkJ70z0rhxudms0TN6URiTrCFYI+ZXQz8FHjde67RQZZ5HBhcy/QrgXnOuf7ACcDfzSwxyDxSjxonxPPQ8HwS4o3RE6bz/W41pxOJJcEWgsuAo4DbnXNLzCwHmFDbAs65yUBZbbMALc3MgBbevHuDzCP1rH1KU+4blsfCNVu55eU5OKcfm4nEiqAKgXNunnNujHNukpmlAi2dc3fWcd3jgJ7AKmAOcI1zrtqvrpjZ5WZWbGbF69atq+NqpSbHd8tkzI+68uKMb5k0bYXfcUQkTIL91tBHZpZkZmnALOAxM7unjus+DSgB2gEDgHFmllTdjM65R5xzhc65wszMzDquVmoz5qSuDOqawR9f/Yo5K9WcTiQWBHtqKNk5twU4F3jMOVcAnFzHdV8GvOgCFgNLgB51fE2po/g44/5heWS0CDSn27Rjt9+RRCTEgi0ECWbWFriQ/14srqvlwEkAZtYa6A6U1tNrSx2kNU/kweH5rNmyk+ufnaXmdCINXLCF4FbgHeAb59yXZpYLfF3bAmY2CfgC6G5mK81spJmNMrNR3iy3AUeb2RzgfeA3zjk1vokQeR1T+d8hvfhgwVrGf6zmdCINmUXbt0MKCwtdcXGx3zFignOOMU+X8MbsVTw5sohjumT4HUlEDpOZTXfOFVY3LdiLxR3M7CXvB2JrzOwFM+tQvzEl0pgZd57bl9zMFoyZNJPvNqs5nUhDFOypoceAVwl8w6c98Jr3nDRwzRsn8PCIfL7fo+Z0Ig1VsIUg0zn3mHNur3d7HND3OGNEl1Yt+et5/ShetpE731JzOpGGJthCsN7MRphZvHcbAWwIZTCJLD/u345Lj87m358u4c05ak4n0pAEWwh+RuCro98Bq4HzCfwOQGLIb8/oSV7HFH79/GxK123zO46I1JNgW0wsd86d5ZzLdM61cs6dTeDHZRJDEhPiePCSfBIT4hg9YQY7dqs1lEhDUJcRyq6vtxQSNdqlNOX+YQNYtHYrt7w0V83pRBqAuhQCq7cUElUGdc3k2pO68dLMb5k4dbnfcUSkjupSCPRWMIZd/aMuHN8tk1tfm8fslZv8jiMidVBrITCzrWa2pZrbVgK/KZAYFRdn3HfRADJbNmb0hBls3K7mdCLRqtZC4Jxr6ZxLqubW0jmXEK6QEplSveZ0a7fu5LpnS9ScTiRK1eXUkAgDslL4/Zm9+GjhOh78cLHfcUTkMKgQSJ2NOLITQwe04573FvHp12ogKxJtVAikzsyMO87tS9dWLRjz9ExWb/7e70gicghUCKReNEtMYPyIAnbtKefKiTPYvVfN6USihQqB1JvOmS246/z+zFi+iTvemu93HBEJkgqB1Ksh/dpy2THZPPbZUl6fvcrvOCISBBUCqXc3n96T/I4p/Ob52Sxeq+Z0IpFOhUDqXWJCHA8Oz6dxo3hGT5jO9l1qTicSyVQIJCTaJjdl7LA8Fq/bxm9fmqPmdCIRTIVAQubYrhlcf3I3XilZxYQpy/yOIyI1UCGQkLryxC6c2D2TW1+fR8kKNacTiUQqBBJScXHGvRcNoFXLJlw5Uc3pRCKRCoGEXEqzRMaPyGfd1l1c+4ya04lEGhUCCYt+HVL4/Y978fGidTzwgZrTiUQSFQIJm+FFHTk3rz33vb+IyYvW+R1HRDwqBBI2Zsbt5/SlW6uWXPP0TFZtUnM6kUigQiBh1TQxnvEj8tlT7rhCzelEIoIKgYRdbmYL7jq/HyUrNvGXN9WcTsRvKgTiizP6tmXksTk8/vlSXp2l5nQiflIhEN/cdHoPCjulctMLs/l6zVa/44jErJAVAjN71MzWmtncGqbfaGYl3m2umZWbWVqo8kjkaRQfx7hL8mmWGM/oiTPUnE7EJ6H8RPA4MLimic65u51zA5xzA4CbgY+dc2UhzCMRqE1yE8YOy6N03TZuelHN6UT8ELJC4JybDAR7YL8YmBSqLBLZju6Swa9O7c5rs1bxxBdqTicSbr5fIzCzZgQ+ObxQyzyXm1mxmRWvW6cfIjVEo4/vzEk9WvHnN+YxY/lGv+OIxBTfCwHwY+Cz2k4LOececc4VOucKMzMzwxhNwiUuzrjnwgG0TmrCVRNnUKbmdCJhEwmFYBg6LSRAcrNGjB9ewPptu7nm6ZmUqzmdSFj4WgjMLBk4HnjFzxwSOfp2SOaPZ/Xmk6/XM/b9r/2OIxITEkL1wmY2CTgByDCzlcAfgEYAzrmHvdnOAf7jnNseqhwSfS4emMX0ZRsZ+8HX5HVM4YTurfyOJNKgWbR9Xa+wsNAVFxf7HUNC7Pvd5Zzz0Gd8t2Unb4wZRPuUpn5HEolqZjbdOVdY3bRIuEYgcoBAc7oCyr3mdLv2lvsdSaTBUiGQiJWT0Zy7L+jHrBWb+PPrak4nEioqBBLRBvdpyy8G5fDklGW8UvKt33FEGiQVAol4vx7cgyOyU7nphTksUnM6kXqnQiARr6I5XfPGCYyaMJ1tak4nUq9UCCQqtE5qwgMX57F0/XZ+88JsNacTqUcqBBI1juqczg2ndeeN2at5/POlfscRaTBUCCSqjDquMyf3bMXtb8xn+jI1pxOpDyoEElXi4oy/XzCAtilNuOqpGWzYtsvvSCJRT4VAok5Fc7oN23dzzdMlak4nUkcqBBKV+rRP5rahvfl08Xruf2+R33FEopoKgUSti47oyAUFHRj7wWI+XLDW7zgiUUuFQKLabWf3oWfbJK59poQVZTv8jiMSlVQIJKo1aRTP+OH57NvnuPIpNacTORwqBBL1sjOa87cL+zN75WZufW2e33FEoo4KgTQIp/Vuwy+Py2Xi1OW8NHOl33FEoooKgTQYN57WnYE5adz84hwWfqfmdCLBUiGQBiMhPo5xF+fRonEjRk+Yztade/yOJFIvyvc55n67mWUbQjOqrwqBNCitkpow7pI8lpXtUHM6iVp7y/cxa8UmHpn8DSMf/5IBt/6HMx/4lCe/WBaS9YVs8HoRvxyZm86Np3XnzrcW8OhnSxl5bI7fkURqtad8H7NXbmbqkg1MLS1j+rKN+9ut52Y058x+bSnKSeeozukhWb8KgTRIvzwul+nLNnLHm/Pp3yGZwuw0vyOJ7LdrbzmzVmxmaukGpi4JHPi/3xP46nPXVi04O68dRTnpFOWk0SqpScjzWLR9dC4sLHTFxcV+x5AosPn7PZw17lN27innjTGDyGjR2O9IEqN27iln5vJN+9/xz1i+kV179wHQo01LinLSODI3nSNy0kK2n5rZdOdcYXXT9IlAGqzkpo14aHg+5z70Odc8PZMnflZEfJz5HUtiwI7de5mx7L8H/pIVm9hdvg8z6NU2ieFFnSjKTWNgdhqpzRP9jqtCIA1b73bJ3HZ2H379/GzufXcRN5zW3e9I0gBt27WX4qVlTF1SxtTSDcxeuZm9+xzxcUafdklcekw2RTlpFGankdy0kd9xD6BCIA3ehYVZTF+6kXEfLiavYwon9WztdySJcpu/3/ODA//cVVso3+dIiDP6dkjmF8fl7j/wt2gc+YfZyE8oUg/+NLQ3c77dzHXPlPDGmEFkpTXzO5JEkU07djNtiXfgX7KBeau2sM9BYnwc/bOSGX18Z4py0yjolEqzxOg7rOpiscSM5Rt2MOSBT+iU3oznRx1Nk0bxfkeSCLVh2679B/4ppRtYuGYrzkFiQhz5HVMC3+jJTSO/Y2rU7Ee6WCwCdExvxj0XDuAXTxTzp9fmcce5ff2OJBFi7dadTC0t239x9+u12wBo0iiOwk5pDOnblqLcdPpnJdM4IToO/IdChUBiyim9WjPq+M48/PE3FHZK5byCDn5HEh98t3knU5dsYEpp4Bx/6fpA64bmifEUZKdxdl57jsxNo2/7FBITGn4DBhUCiTk3nNqNkhUbueXlOfRun0SPNkl+R5IQW7lxx3/f8S8pY9mGwCBGLRsncEROGhcdkUVRbjp92iWREN/wD/xV6RqBxKS1W3dy5thPad44gVeuOoakJpH3lT45PM45lpcFDvxTvFM93276Hgj8tmRgTtr+H3D1bJsUM78t8eUagZk9CpwJrHXO9alhnhOA+4BGwHrn3PGhyiNSWauWTRh3ST4X/3MKv35uNuNH5GMWGweEhsY5x5L12/df2J1aWsZ3W3YCkNY8kYHZafx8UA5FOen0aNOSuBg58B+KUJ4aehwYBzxR3UQzSwEeAgY755abWasQZhE5wMCcNH4zuDt/eXMB//50CT8flOt3JAmCc47Fa7cxxfsO/9QlZazbuguAjBaNKcpN48icNIpy0+naqoUKfBBCVgicc5PNLLuWWS4BXnTOLffmXxuqLCI1+cUgrzndWwvon5XCEWpOF3H27XMsXLN1/0F/2pIyNmzfDUCbpCYc3Tl9/9c5czOa68B/GEJ6jcArBK9Xd2rIzCpOCfUGWgL3O+dq+vRwOXA5QMeOHQuWLQtNT26JTVt27uGsBz5lx+5Ac7rMlmpO56fyfY75q7cETvMsKePLpWVs2hEYZKh9SlOKctIC7/pz0+mY1kwH/iDVdo3Az0IwDigETgKaAl8AQ5xzi2p7TV0sllCYv3oL5zz0GXlZqTw5cmBMfnPEL3vL9/HVqi37v8M/bWkZW3cGevF3TGvmHfgDLZn1i/DDF6k/KFtJ4ALxdmC7mU0G+gO1FgKRUOjZNok/n92XG56bxd/fXcRvBvfwO1KDFewgLEW5abRNbupz2tjgZyF4BRhnZglAIlAE3OtjHolx5xd0YPqyMsZ/9A35HVM5pZea09WH2gZh6dKqBUMHtKMoN50jwzQIixwolF8fnQScAGSY2UrgDwSuCeCce9g5N9/M3gZmA/uAfznn5oYqj0gw/vDjQHO6658t4Y2rB9ExXaciDtXBBmG5sLADRbnpDAzhICxyaPSDMpEqVpTtYMjYT8hKa8YLo9Wc7mAONghLxWmeSBmEJVZF6jUCkYiUldaMey8awMj/K+aPr37Fnef18ztSRKlpEJY4gz7tk/np0Z0oyknniOw0kpvpF9vRQIVApBon9WzNFSd05qGPvqGgUyoXFGb5Hck3W3Z6g7CUBn65W3UQlp8PyqUoN43CTqm0VKuOqKRCIFKD60/pxszlm/jfl+fSu10yvdrFRnO6mgZhaRRvDMhK2T8IS37HVJpHwehbcnC6RiBSi3VbdzFk7Cc0S4zn1auPbZDN6WobhCUvK2X/N3ryOqbSNFHXS6KVrhGIHKbMlo15cHg+wx6Zwg3PzuIf/1MQ9b9kXbt1J9MqNWirPAhLQadUruvbjaKcNPpnpehCeYxQIRA5iCOy07j59B78+Y35/POTUi4/rrPfkQ7JDwZhWbKB0nWxPQiLHEiFQCQII4/NYfqyjfz17YX07xA4XRKpahuEpTA7lYsKY3sQFjmQrhGIBGnrzj2cNe4ztu3ayxtjjqVVS/9/BeucY0XZ90wp3VDtICxHZKdxZG4aRTnp9GoXO4OwyIF8azoXCioE4qcF323h7Ac/o1+HFJ76eVHY31FXHoSlomXD6s0/HISlyDvwaxAWqUwXi0XqSY82SfzlnL5c/+ws7v7PQm4+vWdI11f7ICyJ+7/RU5SbTpfMFjrwy2FRIRA5ROfmd6B42Ub+8XEpBR1TObV3m3p77doGYWmd1JijctP3v+PvnKlBWKR+qBCIHIbfn9mLOSs386vnZvF6m5Z0Sm9+WK9TMQhLxameaVUGYTm+W+b+A3+ndA3CIqGhawQih2lF2Q7OfOBT2qU05aUrgmtOp0FYxC+6RiASAoHmdP352ePF/P6Vudx1fv8D5qltEJacjOYM6dt2/zv+dikahEX8oUIgUgc/6tGaq07swrgPF1PYKY2hee0CB37vHH/x0uoHYSnKSaO1BmGRCKFTQyJ1VL7P8ZNHpzJtSRlxZj8YhKXiVI8GYRG/6dSQSAjFxxn3D8vjlpfm0C6lKUU5gQN/mgZhkSihQiBSDzJaNOYf/1Ptmy2RiKdGIyIiMU6FQEQkxqkQiIjEOBUCEZEYp0IgIhLjVAhERGKcCoGISIxTIRARiXFR12LCzNYByw5z8QxgfT3GqS+RmgsiN5tyHRrlOjQNMVcn51xmdROirhDUhZkV19Rrw0+RmgsiN5tyHRrlOjSxlkunhkREYpwKgYhIjIu1QvCI3wFqEKm5IHKzKdehUa5DE1O5YuoagYiIHCjWPhGIiEgVKgQiIjGuwRQCMxtsZgvNbLGZ3VTN9MZm9ow3faqZZVeadrP3/EIzOy3Mua43s3lmNtvM3jezTpWmlZtZiXd7Ncy5LjWzdZXW//NK035qZl97t5+GOde9lTItMrNNlaaFcns9amZrzWxuDdPNzMZ6uWebWX6laaHcXgfLNdzLM9vMPjez/pWmLTWzOd72qtfxX4PIdYKZba707/X7StNq3QdCnOvGSpnmevtUmjctJNvLzLLM7EMzm29mX5nZNdXME9r9yzkX9TcgHvgGyAUSgVlAryrzXAE87N0fBjzj3e/lzd8YyPFeJz6MuU4Emnn3R1fk8h5v83F7XQqMq2bZNKDU+zPVu58arlxV5r8aeDTU28t77eOAfGBuDdPPAN4CDDgSmBrq7RVkrqMr1gecXpHLe7wUyPBpe50AvF7XfaC+c1WZ98fAB6HeXkBbIN+73xJYVM3/x5DuXw3lE8FAYLFzrtQ5txt4GhhaZZ6hwP95958HTjIz855/2jm3yzm3BFjsvV5YcjnnPnTO7fAeTgE61NO665SrFqcB7zrnypxzG4F3gcE+5boYmFRP666Vc24yUFbLLEOBJ1zAFCDFzNoS2u110FzOuc+99UL49q9gtldN6rJv1neusOxfzrnVzrkZ3v2twHygfZXZQrp/NZRC0B5YUenxSg7ckPvncc7tBTYD6UEuG8pclY0kUPUrNDGzYjObYmZn11OmQ8l1nvcx9HkzyzrEZUOZC+8UWg7wQaWnQ7W9glFT9lBur0NVdf9ywH/MbLqZXe5DnqPMbJaZvd03NiYAAAY8SURBVGVmvb3nImJ7mVkzAgfUFyo9HfLtZYFT1nnA1CqTQrp/NZTB662a56p+L7ameYJZ9nAF/dpmNgIoBI6v9HRH59wqM8sFPjCzOc65b8KU6zVgknNul5mNIvBp6kdBLhvKXBWGAc8758orPReq7RUMP/avoJnZiQQKwbGVnj7G216tgHfNbIH3jjkcZhDofbPNzM4AXga6EiHbi8Bpoc+cc5U/PYR0e5lZCwKF51rn3Jaqk6tZpN72r4byiWAlkFXpcQdgVU3zmFkCkEzgI2Iwy4YyF2Z2MnALcJZzblfF8865Vd6fpcBHBN4phCWXc25DpSz/BAqCXTaUuSoZRpWP7SHcXsGoKXsot1dQzKwf8C9gqHNuQ8XzlbbXWuAl6u+U6EE557Y457Z5998EGplZBhGwvTy17V/1vr3MrBGBIjDROfdiNbOEdv+q7wsfftwIfLIpJXCqoOICU+8q81zJDy8WP+vd780PLxaXUn8Xi4PJlUfg4ljXKs+nAo29+xnA19TTRbMgc7WtdP8cYIr778WpJV6+VO9+WrhyefN1J3DhzsKxvSqtI5uaL34O4YcX86aFensFmasjgeteR1d5vjnQstL9z4HBYczVpuLfj8ABdbm37YLaB0KVy5te8SaxeTi2l/f3fgK4r5Z5Qrp/1dvG9ftG4Kr6IgIH1Vu8524l8C4boAnwnPefYhqQW2nZW7zlFgKnhznXe8AaoMS7veo9fzQwx/uPMAcYGeZcdwBfeev/EOhRadmfedtxMXBZOHN5j/8I3FlluVBvr0nAamAPgXdhI4FRwChvugEPernnAIVh2l4Hy/UvYGOl/avYez7X21azvH/nW8Kc66pK+9cUKhWq6vaBcOXy5rmUwBdIKi8Xsu1F4HSdA2ZX+nc6I5z7l1pMiIjEuIZyjUBERA6TCoGISIxTIRARiXEqBCIiMU6FQEQkxqkQiIjEOBUCiWhm5szs75Ue32Bmf6yn137czM6vj9cKcn1jvFbDE8O1zirrD+vfV6KHCoFEul3AuV77gYhhZvGHsdgVwBnOueH1nUekLlQIJNLtJTBg93VVJ1R9h2tm27w/TzCzj83sWQsMXnOnN0DLNG9gkc6VXuZkM/vEm+9Mb/l4M7vbzL70uq/+stLrfmhmTxH4dWe1LDDY0Fzvdq333MMEfp36qpkd8Hfx5mnuDZzypZnNNLOh3vOXmtkrZva2N2DLH2pbl/f8T7zss8zsyUqrOc4CA9SU6tOBVGgo3UelYXsQmG1mdx3CMv2BngR6xpQC/3LODfRGf7oaqDhoZhPo+NoZ+NDMugA/ATY7544ws8bAZ2b2H2/+gUAfFxi74gBmVgBcBhQRaAsw1cw+ds6NMrPBwInOufU1ZL6FwEAoPzOzFGCamb1Xeb3ADuBLM3uDQFuCA9YF7PZe6xjn3HrzRtjytCXQ0qAH8CqBsTkkxqkQSMRzzm0xsyeAMcD3QS72pXNuNYCZfQNUHMjnEBgVrsKzzrl9wNdmVkrgAHkq0K/SO+ZkAi2SdxNo9lVtEfAcC7zknNvurftFYBAwM4jMpwJnmdkN3uMmBJrGQWDwkQ2VXrOiP01163IEWnSvB3A/bKX8svf3nWdmrYPIJDFAhUCixX0Eetg/Vum5vXinN73R5hIrTdtV6f6+So/38cP9vmqzrYoe71c7596pPMHMTgC2HyRndf3hg2XAec65hVXWW1RLzppep6YmYruqzCeiawQSHbx3tc8S6BZZYSn/HSdhKNDoMF76AjOL864b5BLoQPsOMNrrEY+ZdTOz5kG+3mTgbDNr5i1zDvBJkMu+A1ztFTXMrPJ4CqeYWZqZNQXOBj6rZV3vAxeaWbr3OpVPDYkcQJ8IJJr8nUD74gr/BF4xs2kEDn4He7denYXAx0BrAi1/d5rZvwhcO5jhHZTXETj4HpRzboaZPU6g1TkErk0Ec1oI4DYCn3xme+tdCpzpTfsUeBLoAjzlnCuGwAXz6tZlZrcDH5tZOYHTUpcGmUFikNpQi0Q4M7uUQP/5qw42r8jh0KkhEZEYp08EIofBO//+fjWTTnKVxgWuYdnLgGuqPP2Zc+7K+soncihUCEREYpxODYmIxDgVAhGRGKdCICIS41QIRERi3P8DAT5VedbvlEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Number_of_epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_box)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "y_pred : 推定値のndarray (n_samples,)\n",
    "y_val : 検証データの正解ラベル(n_samples,)\n",
    "X_val : 検証データの特徴量（n_samples, n_features)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "num = 36 # いくつ表示するか\n",
    "true_false = y_pred==y_val.argmax(1)\n",
    "false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "if false_list.shape[0] < num:\n",
    "    num = false_list.shape[0]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "for i in range(num):\n",
    "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
    "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
